{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "import json\n",
    "import math\n",
    "import string\n",
    "import time\n",
    "import numpy as np\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "from IPython.core.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"tea_data.json\", \"r\") as f: \n",
    "    tea_data = json.load(f)[\"data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize the data\n",
    "tokenizer = TreebankWordTokenizer()\n",
    "for tea in tea_data:\n",
    "    tea['about_toks'] = tokenizer.tokenize(tea['about'])\n",
    "    reviews_acc = \"\".join(tea['reviews'])\n",
    "    tea['review_toks'] = tokenizer.tokenize(reviews_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tea_categories = [tea[\"tea_category\"] for tea in tea_data]\n",
    "num_teas = len(tea_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_chars = [('a', 'q'), ('a', 's'), ('a', 'z'), ('b', 'g'), ('b', 'm'), ('b', 'n'), ('b', 'v'), ('c', 'd'),\n",
    "             ('c', 'v'), ('c', 'x'), ('d', 'c'), ('d', 'e'), ('d', 'f'), ('d', 's'), ('e', 'd'), ('e', 'r'),\n",
    "             ('e', 'w'), ('f', 'd'), ('f', 'g'), ('f', 'r'), ('f', 'v'), ('g', 'b'), ('g', 'f'), ('g', 'h'),\n",
    "             ('g', 't'), ('h', 'g'), ('h', 'j'), ('h', 'm'), ('h', 'n'), ('h', 'y'), ('i', 'k'), ('i', 'o'),\n",
    "             ('i', 'u'), ('j', 'h'), ('j', 'k'), ('j', 'u'), ('k', 'i'), ('k', 'j'), ('k', 'l'), ('l', 'k'),\n",
    "             ('l', 'o'), ('m', 'b'), ('m', 'h'), ('n', 'b'), ('n', 'h'), ('o', 'i'), ('o', 'l'), ('o', 'p'),\n",
    "             ('p', 'o'), ('q', 'a'), ('q', 'w'), ('r', 'e'), ('r', 'f'), ('r', 't'), ('s', 'a'), ('s', 'd'),\n",
    "             ('s', 'w'), ('s', 'x'), ('t', 'g'), ('t', 'r'), ('t', 'y'), ('u', 'i'), ('u', 'j'), ('u', 'y'), \n",
    "             ('v', 'b'), ('v', 'c'), ('v', 'f'), ('w', 'e'), ('w', 'q'), ('w', 's'), ('x', 'c'), ('x', 's'), \n",
    "             ('x', 'z'), ('y', 'h'), ('y', 't'), ('y', 'u'), ('z', 'a'), ('z', 'x')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edit Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insertion_cost(text, j): \n",
    "    return 1\n",
    "\n",
    "def deletion_cost(query, j):\n",
    "    return 1\n",
    "\n",
    "def substitution_cost(query, text, i, j):\n",
    "    if query[i-1] == text[j-1]:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "def substitution_cost_adj(query, text, i, j):\n",
    "    a, b = query[i - 1], message[j - 1]\n",
    "    if (a == b): \n",
    "        return 0\n",
    "    elif ((a, b) in adj_chars):\n",
    "        return 1.5\n",
    "    else: \n",
    "        return 2\n",
    "    \n",
    "def edit_matrix(query, text, ins_cost_func, del_cost_func, sub_cost_func):\n",
    "    m = len(query) + 1\n",
    "    n = len(message) + 1\n",
    "\n",
    "    chart = {(0, 0): 0}\n",
    "    for i in range(1, m): \n",
    "        chart[i,0] = chart[i-1, 0] + del_cost_func(query, i) \n",
    "    for j in range(1, n): \n",
    "        chart[0,j] = chart[0, j-1] + ins_cost_func(message, j)\n",
    "    for i in range(1, m):\n",
    "        for j in range(1, n):\n",
    "            chart[i, j] = min(\n",
    "                chart[i-1, j] + del_cost_func(query, i),\n",
    "                chart[i, j-1] + ins_cost_func(message, j),\n",
    "                chart[i-1, j-1] + sub_cost_func(query, message, i, j)\n",
    "            )\n",
    "    return chart\n",
    "\n",
    "def edit_distance(query, text, ins_cost_func, del_cost_func, sub_cost_func):\n",
    "    query = query.lower()\n",
    "    message = message.lower()\n",
    "    \n",
    "    m = len(query)\n",
    "    n = len(message)\n",
    "    edit_mat = edit_matrix(query, message, ins_cost_func, del_cost_func, sub_cost_func)\n",
    "    return edit_mat[m, n]\n",
    "\n",
    "def edit_distance_search(query, teas, ins_cost_func, del_cost_func, sub_cost_func):\n",
    "    search_res = []\n",
    "    tea_categories = [tea[\"tea_category\"] for tea in teas]\n",
    "    \n",
    "    \n",
    "    for category in tea_categories:\n",
    "        edit_dist = edit_distance(query, category, ins_cost_func, del_cost_func, sub_cost_func)\n",
    "        search_res.append((edit_dist, category))\n",
    "    \n",
    "    search_res.sort(key=lambda x: x[0])\n",
    "    return search_res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inverted Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_inverted_index(teas):\n",
    "    inv_index = {}\n",
    "    \n",
    "    for doc_index in range(len(teas)): \n",
    "        tea = teas[doc_index]\n",
    "        doc_dict = {} \n",
    "        tokens = tea['about_toks'] + tea['review_toks']\n",
    "        \n",
    "        for token in tokens:\n",
    "            if token in doc_dict: \n",
    "                doc_dict[token] += 1\n",
    "            else: \n",
    "                doc_dict[token] = 1\n",
    "        \n",
    "        for token, token_count in doc_dict.items(): \n",
    "            if token in inv_index: \n",
    "                inv_index[token].append((doc_index, token_count))\n",
    "            else: \n",
    "                inv_index[token] = [(doc_index, token_count)]\n",
    "            \n",
    "    return inv_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_idf(inv_idx, n_docs, min_df=10, max_df_ratio=0.95):\n",
    "    \"\"\"\n",
    "    returns dict such that for each term, the dict contains the idf value.\n",
    "    \"\"\"\n",
    "    idf_idx = {}\n",
    "    for term in inv_idx:\n",
    "        df = len(inv_idx[word])\n",
    "        if df >= min_df and (df / n_docs) <= max_df_ratio:\n",
    "            idf_idx[term] = np.log2(n_docs / (1 + df))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Doc Norms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_doc_norms(index, idf, n_docs=num_teas):\n",
    "    \"\"\"\n",
    "    index must be a dict, idf must be a dict.\n",
    "    \"\"\"\n",
    "    result = np.zeros(n_docs)\n",
    "    \n",
    "    for word in idf:\n",
    "        for doc, occur in index[word]:\n",
    "            result[doc] += (occur * idf[word])**2 \n",
    "            \n",
    "    return np.sqrt(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accumulate_dot_scores(query_word_counts, index, idf):\n",
    "    \"\"\" computer numerator term for cosin similarity\n",
    "    query_word_counts must be a dict (in the demo it will only be one word)\"\"\"\n",
    "    result = {}\n",
    "    for word in query_word_counts: \n",
    "        if word in index:\n",
    "            for doc,count in index[word]: \n",
    "                if doc in result: \n",
    "                    result[doc]+= query_word_counts[word] * idf[word] * idf[word] * count \n",
    "                else: \n",
    "                    result[doc] = query_word_counts[word] * idf[word] * idf[word] * count \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_search(query, index, idf, doc_norms, score_func=accumulate_dot_scores, tokenizer=treebank_tokenizer):\n",
    "    \"\"\"returns a list of tuples (score, doc_id), a sorted list of results such that the first element has the \n",
    "    highest score, and `doc_id` points to the document with the highest score.\"\"\"\n",
    "    result = []\n",
    "    tokens = tokenizer.tokenize(query.lower())\n",
    "    query_dict = {}\n",
    "    \n",
    "    for word in tokens: \n",
    "        if word in index: \n",
    "            if word in query_dict: \n",
    "                query_dict[word]+=1\n",
    "            else: \n",
    "                query_dict[word] = 1\n",
    "    \n",
    "    query_norm = 0 \n",
    "    for word in tokens: \n",
    "        if word in idf: \n",
    "            query_norm += (query_dict[word] * idf[word])**2\n",
    "    query_norm = math.sqrt(query_norm)\n",
    "    \n",
    "    num = score_func(query_dict, index, idf)\n",
    "    for i in range(len(doc_norms)):\n",
    "        score = 0\n",
    "        if i in num:\n",
    "            result.append(((num[i])/(query_norm * doc_norms[i]),i))\n",
    "    return sorted(result, key = lambda x:x[0], reverse = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs4300-env",
   "language": "python",
   "name": "cs4300-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
