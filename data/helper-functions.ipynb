{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4340a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import re \n",
    "import matplotlib.pyplot as plt \n",
    "import statistics \n",
    "from nltk.tokenize import TreebankWordTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "272fdd96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sql extension is already loaded. To reload it, use:\n",
      "  %reload_ext sql\n"
     ]
    }
   ],
   "source": [
    "#SQL set up\n",
    "import duckdb, sqlalchemy\n",
    "%load_ext sql\n",
    "\n",
    "%config SqlMagic.autopandas = True\n",
    "%config SqlMagic.feedback = False\n",
    "%config SqlMagic.displaycon = False\n",
    "\n",
    "%sql duckdb:///:memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09ed311a",
   "metadata": {},
   "outputs": [],
   "source": [
    "treebank_tokenizer = TreebankWordTokenizer()\n",
    "\n",
    "df = pd.read_csv('./archive/simplified_coffee.csv')\n",
    "#placeholder until we get database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f44fde37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returning data to local variable reviews\n"
     ]
    }
   ],
   "source": [
    "%sql reviews << SELECT review FROM df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e208ac84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returning data to local variable names\n"
     ]
    }
   ],
   "source": [
    "%sql names << SELECT name FROM df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a8800547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(type(names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5979651",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hard code query for sake of demo\n",
    "query = 'citrus chocolate bean'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eaeb3537",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    \"\"\"Returns a list of words that make up the text.\n",
    "    Params: {text: String}\n",
    "    Returns: List\n",
    "    \"\"\"\n",
    "    return re.findall('[a-z]+', text.lower())\n",
    "\n",
    "def tokenize_reviews(reviews, names):\n",
    "    '''\n",
    "    Returns a dictionary with all reviews and their tokenized words\n",
    "    '''\n",
    "    tokens = set()\n",
    "    review_dict = dict()\n",
    "    for i in range(len(reviews)):\n",
    "        print(reviews[0])\n",
    "        review_dict[names[i]] = tokenize(reviews[i])\n",
    "    return review_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b8fc9f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1246\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3620\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/_libs/index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/_libs/index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [24]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m review_dict \u001b[38;5;241m=\u001b[39m \u001b[43mtokenize_reviews\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreviews\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnames\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [23]\u001b[0m, in \u001b[0;36mtokenize_reviews\u001b[0;34m(reviews, names)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(reviews))\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(reviews)):\n\u001b[0;32m---> 16\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mreviews\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     17\u001b[0m     review_dict[names[i]] \u001b[38;5;241m=\u001b[39m tokenize(reviews[i])\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m review_dict\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3504\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3505\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3507\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3623\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3624\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3625\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3626\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3627\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3628\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "review_dict = tokenize_reviews(reviews, names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca8db646",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard(x,y):\n",
    "    num =set(x).intersection(set(y))\n",
    "    denom = len(x) + len(y) - len(num)\n",
    "    return float(len(num) / denom)\n",
    "\n",
    "def build_cbeans_sims_jac(n_cbeans, input_query_cats, input_data):\n",
    "    \"\"\"Returns a cbeans_sims_jac matrix of size (num_cbeans,num_cbeans) where for (i,j) :\n",
    "        [i,j] should be the jaccard similarity between the category sets for cbeans i and j\n",
    "        such that cbeans_sims_jac[i,j] = cbeans_sims_jac[j,i]. \n",
    "        \n",
    "    \n",
    "    Params: {n_bean: Integer, the number of coffeebeans,\n",
    "            input_data: List<Dictionary>, a list of dictionaries where each dictionary \n",
    "                     represents the review_data including the script and the metadata of each movie script}\n",
    "            input_query_cats: user's input query categories\n",
    "    Returns: Numpy Array \n",
    "    \"\"\"\n",
    "    cbeans_sims_jac = np.ones((n_cbeans))\n",
    "    for cbean_idx in range(n_mov):\n",
    "        cat1 = input_data[cbean_idx]['categories']\n",
    "        jac = jaccard(cat1, input_query_cats)\n",
    "        cbeans_sims_jac[movie1_idx, movie2_idx] = jac\n",
    "                \n",
    "    return cbeans_sims_jac\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9166154",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cosim\n",
    "#assume reviews is a dict with bean: tokenized review\n",
    "def build_inverted_index(review_dict):\n",
    "    inverted_index = dict() #dictionary with word: list of tuples\n",
    "    doc_id = 0\n",
    "    for bean, review in review_dict.keys(): #go thru each dict \n",
    "        #create a temp dict for count of words in tokenized_dict\n",
    "        temp_dict = {}\n",
    "        for token in review:\n",
    "            temp_dict[token] = temp_dict.get(token, 0) + 1 #get count of each token\n",
    "        \n",
    "        #go thru every word in temp_dict\n",
    "        for word, count in temp_dict.items():\n",
    "            if word in inverted_index:\n",
    "                inverted_index[word].append( (doc_id, count))\n",
    "            else: \n",
    "                inverted_index[word] = list() #initialize as list first idk if necessary\n",
    "                inverted_index[word].append((doc_id, count))\n",
    "        #move onto next doc\n",
    "        doc_id += 1 \n",
    "        \n",
    "        #now add counts to overall dictionary \n",
    "\n",
    "    return inverted_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2e41a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_idf(inv_idx, n_docs, min_df=10, max_df_ratio=0.95):\n",
    "    \"\"\" Compute term IDF values from the inverted index.\"\"\"\n",
    "    \n",
    "    idf_vals = dict()\n",
    "    max_thresh = max_df_ratio * n_docs\n",
    "    for term, docs in inv_idx.items():\n",
    "        #print(type(docs))\n",
    "        len_docs = len(docs)\n",
    "        if len_docs<=max_thresh and len_docs>=10:\n",
    "            pre_log_idf = (n_docs/(1+len_docs))\n",
    "            idf = math.log2(pre_log_idf)\n",
    "            idf_vals[term] = idf\n",
    "    return idf_vals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97c72c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_doc_norms(index, idf, n_docs):\n",
    "    \"\"\" Precompute the euclidean norm of each document.\n",
    "    \n",
    "    norms: np.array, size: n_docs\n",
    "        norms[i] = the norm of document i.\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    norms = np.zeros(n_docs)\n",
    "    for word in index:\n",
    "        \n",
    "        if word in idf:\n",
    "            idf_weight = idf[word]\n",
    "        else:\n",
    "            idf_weight = 0 #prune to 0\n",
    "        for doc in index[word]:\n",
    "            tf_weight = doc[1]\n",
    "            doc_id = doc[0]\n",
    "            norms[doc_id] += (tf_weight * idf_weight) ** 2\n",
    "    norms = np.sqrt(norms)\n",
    "     #go thru all possible docs, find the word and its invertex index, \n",
    "     #keep sum of product of tf number of times the word i appears in document j * idf[word]\n",
    "    return norms \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19c105b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accumulate_dot_scores(query_word_counts, index, idf):\n",
    "    \"\"\" Perform a term-at-a-time iteration to efficiently compute the numerator term of cosine similarity across multiple documents.\n",
    "   \n",
    "    Returns\n",
    "    =======\n",
    "    \n",
    "    doc_scores: dict\n",
    "        Dictionary mapping from doc ID to the final accumulated score for that doc\n",
    "    \"\"\"\n",
    "\n",
    "    doc_scores = dict() \n",
    "    \n",
    "    for word, qf in query_word_counts.items(): \n",
    "        if word in index:\n",
    "            documents = index[word]\n",
    "            for doc in documents: \n",
    "                doc_id, tf = doc[0], doc[1]\n",
    "\n",
    "                if word not in idf: \n",
    "                    idf_val = 0\n",
    "                else:\n",
    "                    idf_val = idf[word]\n",
    "\n",
    "                acc = idf_val * qf * tf * idf_val\n",
    "                if doc_id not in doc_scores:\n",
    "                    doc_scores[doc_id] = acc\n",
    "                else:\n",
    "                    doc_scores[doc_id] = doc_scores[doc_id] + acc\n",
    "    return doc_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "660ab745",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [36]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m inv_idx \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_inverted_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreview_dict\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#TO DO : CHANGE IT TO A LIST\u001b[39;00m\n\u001b[1;32m      3\u001b[0m idf \u001b[38;5;241m=\u001b[39m compute_idf(inv_idx, \u001b[38;5;28mlen\u001b[39m(review_dict),\n\u001b[1;32m      4\u001b[0m                   min_df\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[1;32m      5\u001b[0m                   max_df_ratio\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m)  \u001b[38;5;66;03m# documents are very short so we can use a small value here\u001b[39;00m\n\u001b[1;32m      6\u001b[0m                                      \u001b[38;5;66;03m# examine the actual DF values of common words like \"the\"\u001b[39;00m\n\u001b[1;32m      7\u001b[0m                                      \u001b[38;5;66;03m# to set these values\u001b[39;00m\n",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36mbuild_inverted_index\u001b[0;34m(reviews)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m tokenized \u001b[38;5;129;01min\u001b[39;00m reviews: \u001b[38;5;66;03m#go thru each dict \u001b[39;00m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m#create a temp dict for count of words in tokenized_dict\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     temp_dict \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m----> 9\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtokenized\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtoks\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m:\n\u001b[1;32m     10\u001b[0m         temp_dict[token] \u001b[38;5;241m=\u001b[39m temp_dict\u001b[38;5;241m.\u001b[39mget(token, \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;66;03m#get count of each token\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m#go thru every word in temp_dict\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "inv_idx = build_inverted_index(review_dict) #TO DO : CHANGE IT TO A LIST\n",
    "\n",
    "idf = compute_idf(inv_idx, len(review_dict),\n",
    "                  min_df=10,\n",
    "                  max_df_ratio=0.1)  # documents are very short so we can use a small value here\n",
    "                                     # examine the actual DF values of common words like \"the\"\n",
    "                                     # to set these values\n",
    "\n",
    "inv_idx = {key: val for key, val in inv_idx.items()\n",
    "           if key in idf}            # prune the terms left out by idf\n",
    "\n",
    "doc_norms = compute_doc_norms(inv_idx, idf, len(review_dict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9e04400a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_search(query, index, idf, doc_norms, score_func=accumulate_dot_scores, tokenizer=TreebankWordTokenizer):\n",
    "    \"\"\" Search the collection of documents for the given query\n",
    "   \n",
    "    Returns\n",
    "    =======\n",
    "    \n",
    "    results, list of tuples (score, doc_id)\n",
    "        Sorted list of results such that the first element has\n",
    "        the highest score, and `doc_id` points to the document\n",
    "        with the highest score.\n",
    "\n",
    "    \"\"\"\n",
    "    query = query.lower() \n",
    "    query_tokens = tokenizer.tokenize(query)\n",
    "    query_word_counts = dict()\n",
    "    \n",
    "\n",
    "    for word in query_tokens:\n",
    "        query_word_counts[word] = query_word_counts.get(word, 0) + 1 \n",
    "    results = list() \n",
    "    doc_scores = score_func(query_word_counts, index, idf)\n",
    "    #q_norms\n",
    "    q_norm = 0 \n",
    "    for term, freq in query_word_counts.items():\n",
    "        if term in idf:\n",
    "            idf_weight = idf[term]\n",
    "        else:\n",
    "            idf_weight = 0 #prune to 0\n",
    "        q_norm += ((freq  * idf_weight)  ** 2)\n",
    "    q_norm = math.sqrt(q_norm)\n",
    "    \n",
    "    for doc_id, doc_score in doc_scores.items():\n",
    "        cossim_val = doc_score / (doc_norms[doc_id] *  q_norm)\n",
    "        results.append((cossim_val,doc_id))\n",
    "        \n",
    "    results = sorted(results, key=lambda x: x[0], reverse=True)\n",
    "    return results[0:10] #return first top ten similar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d03c150e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'inv_idx' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [38]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m output \u001b[38;5;241m=\u001b[39m index_search(query, \u001b[43minv_idx\u001b[49m, idf, doc_norms)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'inv_idx' is not defined"
     ]
    }
   ],
   "source": [
    "output_scores, output_ids = index_search(query, inv_idx, idf, doc_norms) #score, doc id \n",
    "rel_beans = name_arry[output_ids]\n",
    "rel_beans_revs = rev_array[output_ids]\n",
    "#rel_beans should be top 10 most similar cbeans & reviews & what frontend displays "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f11623",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
